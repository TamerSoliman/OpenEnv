#!/usr/bin/env python3
"""
================================================================================
HEAVILY ANNOTATED: Agent-Environment Interaction Loop
================================================================================

This file demonstrates the COMPLETE agent-environment interaction pattern
used in OpenEnv, based on the Gymnasium API.

WHAT: Shows how agents interact with environments through reset() and step()
HOW: Line-by-line walkthrough of a complete episode execution
WHY: Understanding this loop is essential for building RL agents and
     environment consumers

Source: Based on /home/user/OpenEnv/examples/local_echo_env.py
================================================================================
"""

# ==============================================================================
# IMPORTS AND SETUP
# ==============================================================================

import sys
from pathlib import Path

# Add src to path (typical pattern for running examples)
# WHY: Allows importing from the OpenEnv source code directly
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# Import the environment client and action types
# WHAT: These are the interfaces for talking to the environment
from envs.echo_env import EchoAction, EchoEnv


# ==============================================================================
# MAIN INTERACTION FUNCTION - THE COMPLETE AGENT-ENVIRONMENT LOOP
# ==============================================================================

def main():
    """
    Demonstrates the full agent-environment interaction loop.

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              AGENT-ENVIRONMENT INTERACTION LOOP               â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                               â”‚
    â”‚  1. CREATE ENVIRONMENT                                        â”‚
    â”‚     â””â”€â†’ from_docker_image() or from_hub()                    â”‚
    â”‚                                                               â”‚
    â”‚  2. RESET ENVIRONMENT                                         â”‚
    â”‚     â””â”€â†’ client.reset() â†’ StepResult[Observation]             â”‚
    â”‚                                                               â”‚
    â”‚  3. LOOP UNTIL DONE:                                          â”‚
    â”‚     â”œâ”€â†’ Agent observes current state                         â”‚
    â”‚     â”œâ”€â†’ Agent decides on action                              â”‚
    â”‚     â”œâ”€â†’ client.step(action) â†’ StepResult[Observation]        â”‚
    â”‚     â”œâ”€â†’ Agent receives: observation, reward, done            â”‚
    â”‚     â””â”€â†’ Check if done, else continue loop                    â”‚
    â”‚                                                               â”‚
    â”‚  4. CLEANUP                                                   â”‚
    â”‚     â””â”€â†’ client.close()                                       â”‚
    â”‚                                                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """

    print("=" * 60)
    print("AGENT-ENVIRONMENT INTERACTION LOOP DEMONSTRATION")
    print("=" * 60)
    print()

    # ==========================================================================
    # STEP 1: CREATE ENVIRONMENT CLIENT
    # ==========================================================================
    # WHAT: Initialize connection to the environment
    # HOW: Use from_docker_image() factory method to:
    #      1. Start a Docker container running the environment server
    #      2. Wait for the HTTP server to be ready
    #      3. Create an HTTPEnvClient connected to that server
    # WHY: Abstracts away the complexity of Docker + HTTP setup

    try:
        print("STEP 1: Creating environment client from Docker image")
        print("-" * 60)
        print("  Calling: EchoEnv.from_docker_image('echo-env:latest')")
        print()
        print("  This does:")
        print("    1. docker run -d -p <port>:8000 echo-env:latest")
        print("    2. Wait for HTTP health check at http://localhost:<port>/health")
        print("    3. Create EchoEnv client pointing to http://localhost:<port>")
        print()

        # CRITICAL LINE: Create the environment client
        # TYPE: EchoEnv (which is a subclass of HTTPEnvClient[EchoAction, EchoObservation])
        client = EchoEnv.from_docker_image("echo-env:latest")

        print("âœ“ Client created successfully!")
        print(f"  Client type: {type(client).__name__}")
        print(f"  Base URL: {client._base}")
        print()

        # ==========================================================================
        # STEP 2: RESET THE ENVIRONMENT - START A NEW EPISODE
        # ==========================================================================
        # WHAT: Initialize a new episode and get the initial observation
        # HOW:
        #   1. Client sends HTTP POST to /reset
        #   2. Server calls env.reset()
        #   3. Server returns JSON: {observation: {...}, reward: 0.0, done: false}
        #   4. Client parses JSON into StepResult[EchoObservation]
        # WHY: Every episode must start with reset() to initialize state

        print("STEP 2: Reset environment - initialize new episode")
        print("-" * 60)
        print("  Calling: client.reset()")
        print()
        print("  HTTP Request:")
        print("    POST http://localhost:<port>/reset")
        print("    Body: {}")
        print()

        # CRITICAL LINE: Reset the environment
        # RETURN TYPE: StepResult[EchoObservation]
        result = client.reset()

        print("  HTTP Response (parsed):")
        print(f"    observation: {result.observation}")
        print(f"    reward: {result.reward}")
        print(f"    done: {result.done}")
        print()

        # UNPACK THE RESULT
        # StepResult contains three key fields:
        #   - observation: EchoObservation (environment-specific data)
        #   - reward: float | None (scalar feedback signal)
        #   - done: bool (is episode finished?)

        initial_observation = result.observation  # Type: EchoObservation
        initial_reward = result.reward           # Type: float | None
        initial_done = result.done               # Type: bool

        print("  Unpacked StepResult:")
        print(f"    observation.echoed_message = '{initial_observation.echoed_message}'")
        print(f"    observation.message_length = {initial_observation.message_length}")
        print(f"    reward = {initial_reward}")
        print(f"    done = {initial_done}")
        print()

        # AGENT STATE INITIALIZATION
        # At this point, the agent knows:
        #   - The episode has started (done=False)
        #   - The initial observation (what the environment looks like)
        #   - No reward yet (typically 0.0 after reset)

        print("âœ“ Environment reset complete - episode initialized")
        print()

        # ==========================================================================
        # STEP 3: AGENT-ENVIRONMENT INTERACTION LOOP
        # ==========================================================================
        # WHAT: The core RL loop where agent and environment interact
        # HOW:
        #   1. Agent observes current state (observation from previous step/reset)
        #   2. Agent decides on action (policy: observation â†’ action)
        #   3. Agent executes action via client.step(action)
        #   4. Environment returns new observation, reward, done
        #   5. Agent processes reward (learning update, logging, etc.)
        #   6. Check if done; if not, loop back to step 1
        # WHY: This is the fundamental pattern of reinforcement learning

        print("STEP 3: Agent-environment interaction loop")
        print("-" * 60)
        print()

        # Define a sequence of messages for the agent to send
        # AGENT POLICY: In this simple example, the policy is scripted
        #               (pre-defined messages). In a real RL agent, this would be
        #               a learned policy: Ï€(a|s) = probability of action a given state s

        messages = [
            "Hello, World!",
            "Testing echo environment",
            "One more message",
        ]

        print(f"  Agent policy: Send {len(messages)} pre-defined messages")
        print()

        # -------------------------------------------------------------------------
        # LOOP ITERATION: For each action the agent wants to take
        # -------------------------------------------------------------------------

        for i, msg in enumerate(messages, 1):
            print(f"  â”Œâ”€ ITERATION {i}/{len(messages)} " + "â”€" * 40)
            print(f"  â”‚")

            # =====================================================================
            # SUB-STEP 3.1: AGENT DECISION - CONSTRUCT ACTION
            # =====================================================================
            # WHAT: Agent decides what action to take based on observation
            # HOW: Creates an Action object with the chosen action parameters
            # WHY: Actions must be structured according to environment's schema

            print(f"  â”‚ 3.1 Agent Decision: Construct action")
            print(f"  â”‚     Message to send: '{msg}'")
            print(f"  â”‚")

            # CRITICAL LINE: Create the action object
            # TYPE: EchoAction (subclass of Action)
            # SCHEMA:
            #   - message: str  (the message to echo)
            #   - metadata: dict (optional, inherited from Action base class)

            action = EchoAction(message=msg)

            print(f"  â”‚     Action object: EchoAction(message='{action.message}')")
            print(f"  â”‚")

            # =====================================================================
            # SUB-STEP 3.2: EXECUTE ACTION - ENVIRONMENT TRANSITION
            # =====================================================================
            # WHAT: Send action to environment and receive result
            # HOW:
            #   1. Client serializes action to JSON
            #   2. Client sends HTTP POST to /step with action payload
            #   3. Server deserializes action to EchoAction object
            #   4. Server calls env.step(action)
            #   5. Environment computes next state, reward, done
            #   6. Server serializes observation to JSON
            #   7. Client deserializes JSON to StepResult[EchoObservation]
            # WHY: This is the state transition: s_t, a_t â†’ s_{t+1}, r_t, done

            print(f"  â”‚ 3.2 Execute Action: Send to environment")
            print(f"  â”‚     Calling: client.step(action)")
            print(f"  â”‚")
            print(f"  â”‚     HTTP Request:")
            print(f"  â”‚       POST http://localhost:<port>/step")
            print(f"  â”‚       Body: {{")
            print(f"  â”‚         'action': {{'message': '{msg}'}},"
            print(f"  â”‚         'timeout_s': 15")
            print(f"  â”‚       }}")
            print(f"  â”‚")

            # CRITICAL LINE: Execute the step
            # RETURN TYPE: StepResult[EchoObservation]
            #   Contains: (observation, reward, done)

            result = client.step(action)

            # =====================================================================
            # SUB-STEP 3.3: PROCESS RESULT - OBSERVATION, REWARD, DONE
            # =====================================================================
            # WHAT: Extract and process the environment's response
            # HOW: Unpack StepResult into its components
            # WHY: Agent needs this info for learning and decision-making

            print(f"  â”‚     HTTP Response (parsed):")
            print(f"  â”‚       observation: {result.observation}")
            print(f"  â”‚       reward: {result.reward}")
            print(f"  â”‚       done: {result.done}")
            print(f"  â”‚")

            # UNPACK RESULT
            observation = result.observation  # Type: EchoObservation
            reward = result.reward           # Type: float | None
            done = result.done               # Type: bool

            # OBSERVATION FIELDS (specific to EchoObservation)
            echoed_message = observation.echoed_message  # What was echoed back
            message_length = observation.message_length  # Length of message
            obs_metadata = observation.metadata         # Optional extra info

            print(f"  â”‚ 3.3 Process Result:")
            print(f"  â”‚     Observation:")
            print(f"  â”‚       echoed_message = '{echoed_message}'")
            print(f"  â”‚       message_length = {message_length}")
            print(f"  â”‚       metadata = {obs_metadata}")
            print(f"  â”‚")
            print(f"  â”‚     Reward: {reward}")
            print(f"  â”‚       (In Echo env: reward = message_length * 0.1)")
            print(f"  â”‚")
            print(f"  â”‚     Done: {done}")
            print(f"  â”‚       (In Echo env: never terminates, always False)")
            print(f"  â”‚")

            # =====================================================================
            # SUB-STEP 3.4: AGENT UPDATE (if this were a learning agent)
            # =====================================================================
            # WHAT: Update agent's policy based on received reward
            # HOW: Depends on RL algorithm (Q-learning, policy gradient, etc.)
            # WHY: This is where learning happens in RL
            #
            # PSEUDOCODE FOR RL AGENT:
            #   agent.update(
            #       state=previous_observation,
            #       action=action,
            #       reward=reward,
            #       next_state=observation,
            #       done=done
            #   )
            #
            # IN THIS EXAMPLE: We just print the info (no learning)

            print(f"  â”‚ 3.4 Agent Update: (scripted agent - no learning)")
            print(f"  â”‚     A real RL agent would:")
            print(f"  â”‚       - Store transition: (s_t, a_t, r_t, s_{{t+1}}, done)")
            print(f"  â”‚       - Update policy/value function")
            print(f"  â”‚       - Adjust exploration strategy")
            print(f"  â”‚")

            # =====================================================================
            # SUB-STEP 3.5: CHECK TERMINATION CONDITION
            # =====================================================================
            # WHAT: Determine if episode should end
            # HOW: Check the 'done' flag from environment
            # WHY: Episodes have finite length (goal reached, max steps, etc.)

            print(f"  â”‚ 3.5 Check Termination:")
            print(f"  â”‚     done = {done}")
            if done:
                print(f"  â”‚     â†’ Episode finished! Breaking loop.")
                print(f"  â”‚")
                print(f"  â””" + "â”€" * 56)
                print()
                break  # Exit the loop - episode is over
            else:
                print(f"  â”‚     â†’ Episode continues, moving to next iteration")
                print(f"  â”‚")
                print(f"  â””" + "â”€" * 56)
                print()

            # Loop continues with next action (if not done)

        # ==========================================================================
        # STEP 4: QUERY ENVIRONMENT STATE (OPTIONAL)
        # ==========================================================================
        # WHAT: Get episode metadata from environment
        # HOW: Call client.state() which sends HTTP GET to /state
        # WHY: Useful for logging, debugging, monitoring

        print("STEP 4: Query environment state (optional)")
        print("-" * 60)
        print("  Calling: client.state()")
        print()
        print("  HTTP Request:")
        print("    GET http://localhost:<port>/state")
        print()

        # CRITICAL LINE: Get environment state
        # RETURN TYPE: State (with episode_id and step_count)
        state = client.state()

        print("  HTTP Response (parsed):")
        print(f"    episode_id: {state.episode_id}")
        print(f"    step_count: {state.step_count}")
        print()
        print(f"âœ“ Episode {state.episode_id} completed {state.step_count} steps")
        print()

        # ==========================================================================
        # STEP 5: CLEANUP - STOP ENVIRONMENT
        # ==========================================================================
        # WHAT: Shut down the environment and clean up resources
        # HOW: Call client.close() which stops the Docker container
        # WHY: Free up system resources, prevent container buildup

        print("STEP 5: Cleanup")
        print("-" * 60)
        print("  Calling: client.close()")
        print()
        print("  This does:")
        print("    1. Stop the Docker container")
        print("    2. Remove the container")
        print()

        client.close()

        print("âœ“ Environment closed, container removed")
        print()

        # ==========================================================================
        # SUMMARY
        # ==========================================================================

        print("=" * 60)
        print("INTERACTION LOOP COMPLETED SUCCESSFULLY! ğŸ‰")
        print("=" * 60)
        print()
        print("Summary of what happened:")
        print()
        print("  1. Created environment client (Docker + HTTP)")
        print("  2. Reset environment â†’ received initial observation")
        print(f"  3. Executed {len(messages)} actions:")
        print("     - Agent constructed action")
        print("     - Environment transitioned state")
        print("     - Agent received observation + reward + done")
        print("  4. Queried environment state metadata")
        print("  5. Cleaned up resources")
        print()
        print("This is the fundamental pattern for ALL OpenEnv interactions!")
        print()

        return True

    except Exception as e:
        print(f"\nâŒ Interaction failed: {e}")
        import traceback
        traceback.print_exc()
        return False


# ==============================================================================
# DATA FLOW DIAGRAM
# ==============================================================================
"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         COMPLETE DATA FLOW                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  AGENT CODE                      HTTP                   ENVIRONMENT       â”‚
â”‚  (this file)                                            (Docker)          â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ EchoEnv     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ FastAPI      â”‚   â”‚
â”‚  â”‚ Client      â”‚  1. from_docker_image()              â”‚ HTTP Server  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º              â”‚   â”‚
â”‚        â”‚          Start container, wait for health     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚        â”‚                                                      â”‚           â”‚
â”‚        â”‚ 2. reset()                                           â”‚           â”‚
â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€POST /reset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º      â”‚           â”‚
â”‚        â”‚          {}                                          â”‚           â”‚
â”‚        â”‚                                                      â–¼           â”‚
â”‚        â”‚                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚        â”‚                                              â”‚ EchoEnv      â”‚    â”‚
â”‚        â”‚                                              â”‚ Environment  â”‚    â”‚
â”‚        â”‚                                              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚        â”‚                                                     â”‚            â”‚
â”‚        â”‚                                         env.reset() â”‚            â”‚
â”‚        â”‚                                                     â–¼            â”‚
â”‚        â”‚                                         Create State:           â”‚
â”‚        â”‚                                           episode_id = uuid4()  â”‚
â”‚        â”‚                                           step_count = 0        â”‚
â”‚        â”‚                                                     â”‚            â”‚
â”‚        â”‚                                         Return:     â”‚            â”‚
â”‚        â”‚                                           EchoObservation        â”‚
â”‚        â”‚                                             echoed_message       â”‚
â”‚        â”‚                                             message_length       â”‚
â”‚        â”‚                                             done=False           â”‚
â”‚        â”‚                                             reward=0.0           â”‚
â”‚        â”‚                                                     â”‚            â”‚
â”‚        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚        â”‚          {observation: {...}, reward: 0.0, done: false}         â”‚
â”‚        â”‚                                                                  â”‚
â”‚        â”‚ StepResult[EchoObservation]                                      â”‚
â”‚        â”‚   observation.echoed_message = "Echo environment ready!"        â”‚
â”‚        â”‚   reward = 0.0                                                   â”‚
â”‚        â”‚   done = False                                                   â”‚
â”‚        â”‚                                                                  â”‚
â”‚        â”‚ 3. step(EchoAction(message="Hello"))                             â”‚
â”‚        â”œâ”€â”€â”€â”€â”€â”€POST /step â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º              â”‚
â”‚        â”‚       {action: {message: "Hello"}, timeout_s: 15}               â”‚
â”‚        â”‚                                                      â”‚           â”‚
â”‚        â”‚                                         Deserialize: â”‚           â”‚
â”‚        â”‚                                           EchoAction â”‚           â”‚
â”‚        â”‚                                                      â–¼           â”‚
â”‚        â”‚                                         env.step(action)         â”‚
â”‚        â”‚                                                      â”‚           â”‚
â”‚        â”‚                                         Update:      â”‚           â”‚
â”‚        â”‚                                           step_count += 1        â”‚
â”‚        â”‚                                                      â”‚           â”‚
â”‚        â”‚                                         Compute:     â”‚           â”‚
â”‚        â”‚                                           reward = len * 0.1     â”‚
â”‚        â”‚                                                      â”‚           â”‚
â”‚        â”‚                                         Return:      â”‚           â”‚
â”‚        â”‚                                           EchoObservation        â”‚
â”‚        â”‚                                             echoed_message       â”‚
â”‚        â”‚                                             message_length       â”‚
â”‚        â”‚                                             done=False           â”‚
â”‚        â”‚                                             reward=0.5           â”‚
â”‚        â”‚                                                      â”‚           â”‚
â”‚        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚        â”‚       {observation: {...}, reward: 0.5, done: false}            â”‚
â”‚        â”‚                                                                  â”‚
â”‚        â”‚ StepResult[EchoObservation]                                      â”‚
â”‚        â”‚   observation.echoed_message = "Hello"                           â”‚
â”‚        â”‚   observation.message_length = 5                                 â”‚
â”‚        â”‚   reward = 0.5                                                   â”‚
â”‚        â”‚   done = False                                                   â”‚
â”‚        â”‚                                                                  â”‚
â”‚        â”‚ 4. state()                                                       â”‚
â”‚        â”œâ”€â”€â”€â”€â”€â”€GET /state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º              â”‚
â”‚        â”‚                                                      â”‚           â”‚
â”‚        â”‚                                         env.state    â”‚           â”‚
â”‚        â”‚                                                      â”‚           â”‚
â”‚        â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚        â”‚       {episode_id: "...", step_count: 1}                         â”‚
â”‚        â”‚                                                                  â”‚
â”‚        â”‚ State                                                            â”‚
â”‚        â”‚   episode_id = "abc-123-..."                                     â”‚
â”‚        â”‚   step_count = 1                                                 â”‚
â”‚        â”‚                                                                  â”‚
â”‚        â”‚ 5. close()                                                       â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€ Stop container â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º             â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""


# ==============================================================================
# KEY CONCEPTS DEMONSTRATED
# ==============================================================================
"""
1. EPISODE LIFECYCLE:
   - Episodes start with reset()
   - Episodes progress with step(action)
   - Episodes end when done=True
   - Each episode has unique episode_id

2. ACTION-OBSERVATION LOOP:
   - Agent observes state â†’ decides action â†’ executes action
   - Environment transitions â†’ computes reward â†’ returns new state
   - This repeats until done=True

3. TYPE SAFETY:
   - Actions are typed (EchoAction)
   - Observations are typed (EchoObservation)
   - StepResult[T] wraps observations with reward and done

4. HTTP ABSTRACTION:
   - Client methods (reset, step, state) hide HTTP details
   - Server endpoints (/reset, /step, /state) wrap environment
   - JSON serialization/deserialization is automatic

5. CONTAINER LIFECYCLE:
   - from_docker_image() starts container
   - Container runs throughout interaction
   - close() stops and removes container

6. STATE TRACKING:
   - episode_id uniquely identifies episodes
   - step_count tracks progress within episode
   - State is separate from Observation
"""


# ==============================================================================
# COMPARISON: SCRIPTED AGENT vs RL AGENT
# ==============================================================================
"""
SCRIPTED AGENT (this example):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ for msg in ["Hello", "Test", "Goodbye"]:                       â”‚
â”‚     action = EchoAction(message=msg)  # Fixed policy           â”‚
â”‚     result = client.step(action)                               â”‚
â”‚     # No learning, just execution                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RL AGENT (with learning):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ observation = client.reset().observation                       â”‚
â”‚ done = False                                                   â”‚
â”‚                                                                â”‚
â”‚ while not done:                                                â”‚
â”‚     # Policy: Choose action based on observation              â”‚
â”‚     action = agent.select_action(observation)                 â”‚
â”‚                                                                â”‚
â”‚     # Execute action                                           â”‚
â”‚     result = client.step(action)                              â”‚
â”‚                                                                â”‚
â”‚     # Learn from transition                                    â”‚
â”‚     agent.update(                                              â”‚
â”‚         state=observation,                                     â”‚
â”‚         action=action,                                         â”‚
â”‚         reward=result.reward,                                  â”‚
â”‚         next_state=result.observation,                         â”‚
â”‚         done=result.done                                       â”‚
â”‚     )                                                          â”‚
â”‚                                                                â”‚
â”‚     # Move to next state                                       â”‚
â”‚     observation = result.observation                           â”‚
â”‚     done = result.done                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
